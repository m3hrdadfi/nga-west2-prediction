{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uz8yEFjN4QeL"
   },
   "source": [
    "# NGA-West2 Prediction\n",
    "\n",
    "**Outcome**\n",
    "- Proposed a time series regression based on recurrent neural networks(LSTM).\n",
    "- The aim was to achieve a novel approach for estimating the PGA, and PGV for shallow crustal\n",
    "earthquakes by seven earthquake’s main components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyfyAPWP4VDl"
   },
   "source": [
    "# Prepare DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Z2R-O6P80Wd",
    "outputId": "1ee1b85c-e19d-46e3-ce6f-0eaf58902d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nga_west_v1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "data = 'https://www.dropbox.com/.../nga_west_v1.xlsx'\n",
    "current_dir = '/tmp/nga-prj/'\n",
    "\n",
    "subprocess.run([\"rm\", \"-rf\", current_dir])\n",
    "subprocess.run([\"wget\", data, \"-P\", current_dir])\n",
    "\n",
    "!ls /tmp/nga-prj/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u34o1s9x4X7x"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PbGf9df55Ok"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q xlrd\n",
    "!pip install -U -q scikit-learn\n",
    "!pip install -U -q openpyxl\n",
    "!pip install -U -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhByoRpy7svS"
   },
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
    "\n",
    "# GraphViz\n",
    "!apt-get -qq install -y graphviz && pip install -q pydot\n",
    "\n",
    "# 7zip\n",
    "!apt-get -qq install -y libarchive-dev && pip install -q -U libarchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpiFrw6S4uUL"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import layers\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "from tensorflow.python.ops.init_ops import glorot_uniform_initializer\n",
    "from tensorflow import layers\n",
    "import time\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "plt.style.use('seaborn-ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBRpIMHR4x1x"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "XtsyQXFE4y8C",
    "outputId": "7a787f70-07a4-4eee-e5d9-702d977e56aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Earthquake Magnitude</th>\n",
       "      <th>Dip (deg)</th>\n",
       "      <th>Mechanism Based on Rake Angle</th>\n",
       "      <th>ClstD (km)</th>\n",
       "      <th>FW/HW Indicator</th>\n",
       "      <th>Vs30 (m/s) selected for analysis</th>\n",
       "      <th>Idirectivity</th>\n",
       "      <th>PGA (g)</th>\n",
       "      <th>PGV (cm/sec)</th>\n",
       "      <th>PGD (cm)</th>\n",
       "      <th>...</th>\n",
       "      <th>T8.500S</th>\n",
       "      <th>T9.000S</th>\n",
       "      <th>T9.500S</th>\n",
       "      <th>T10.000S</th>\n",
       "      <th>T11.000S</th>\n",
       "      <th>T12.000S</th>\n",
       "      <th>T13.000S</th>\n",
       "      <th>T14.000S</th>\n",
       "      <th>T15.000S</th>\n",
       "      <th>T20.000S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>na</td>\n",
       "      <td>593.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157020</td>\n",
       "      <td>10.05400</td>\n",
       "      <td>3.005200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>na</td>\n",
       "      <td>551.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.64978</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.57</td>\n",
       "      <td>na</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040961</td>\n",
       "      <td>2.79070</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.98</td>\n",
       "      <td>na</td>\n",
       "      <td>213.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.64551</td>\n",
       "      <td>0.056359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.58</td>\n",
       "      <td>na</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>6.56390</td>\n",
       "      <td>0.733060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Earthquake Magnitude  Dip (deg)  Mechanism Based on Rake Angle  ClstD (km)  \\\n",
       "0                   6.0       75.0                              0        2.86   \n",
       "1                   6.0       75.0                              0        2.92   \n",
       "2                   5.8       90.0                              0       71.57   \n",
       "3                   5.0       90.0                              0       34.98   \n",
       "4                   5.5       90.0                              0       53.58   \n",
       "\n",
       "  FW/HW Indicator  Vs30 (m/s) selected for analysis  Idirectivity   PGA (g)  \\\n",
       "0              na                            593.35             0  0.157020   \n",
       "1              na                            551.82             0  0.046423   \n",
       "2              na                            219.31             0  0.040961   \n",
       "3              na                            213.44             0  0.018449   \n",
       "4              na                            219.31             0  0.122180   \n",
       "\n",
       "   PGV (cm/sec)  PGD (cm)    ...      T8.500S   T9.000S   T9.500S  T10.000S  \\\n",
       "0      10.05400  3.005200    ...     0.001521  0.001368  0.001237  0.001123   \n",
       "1       0.64978  0.035305    ...     0.000021  0.000019  0.000017  0.000015   \n",
       "2       2.79070  0.402240    ...     0.000255  0.000226  0.000201  0.000180   \n",
       "3       0.64551  0.056359    ...     0.000031  0.000027  0.000024  0.000022   \n",
       "4       6.56390  0.733060    ...     0.000401  0.000348  0.000309  0.000276   \n",
       "\n",
       "   T11.000S  T12.000S  T13.000S  T14.000S  T15.000S  T20.000S  \n",
       "0  0.000938  0.000794  0.000681  0.000591  0.000517  0.000295  \n",
       "1  0.000012  0.000010  0.000009  0.000008  0.000007  0.000004  \n",
       "2  0.000147  0.000122  0.000103  0.000088  0.000077  0.000044  \n",
       "3  0.000018  0.000016  0.000013  0.000012  0.000010  0.000006  \n",
       "4  0.000228  0.000193  0.000166  0.000144  0.000126  0.000072  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(os.path.join(current_dir + 'nga_west_v1.xlsx'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AOUZm_x6Gkt"
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Earthquake Magnitude', \n",
    "    'Dip (deg)', \n",
    "    'Mechanism Based on Rake Angle', \n",
    "    'ClstD (km)', \n",
    "    'FW/HW Indicator',\n",
    "    'Vs30 (m/s) selected for analysis',\n",
    "    'Idirectivity'\n",
    "]\n",
    "measures = [\n",
    "    'PGA (g)', 'PGV (cm/sec)', 'PGD (cm)', 'T0.010S', 'T0.020S', 'T0.022S', \n",
    "    'T0.025S', 'T0.029S', 'T0.030S', 'T0.032S', 'T0.035S', 'T0.036S', \n",
    "    'T0.040S', 'T0.042S', 'T0.044S', 'T0.045S', 'T0.046S', 'T0.048S', \n",
    "    'T0.050S', 'T0.055S', 'T0.060S', 'T0.065S', 'T0.067S', 'T0.070S', \n",
    "    'T0.075S', 'T0.080S', 'T0.085S', 'T0.090S', 'T0.095S', 'T0.100S', \n",
    "    'T0.110S', 'T0.120S', 'T0.130S', 'T0.133S', 'T0.140S', 'T0.150S', \n",
    "    'T0.160S', 'T0.170S', 'T0.180S', 'T0.190S', 'T0.200S', 'T0.220S', \n",
    "    'T0.240S', 'T0.250S', 'T0.260S', 'T0.280S', 'T0.290S', 'T0.300S', \n",
    "    'T0.320S', 'T0.340S', 'T0.350S', 'T0.360S', 'T0.380S', 'T0.400S', \n",
    "    'T0.420S', 'T0.440S', 'T0.450S', 'T0.460S', 'T0.480S', 'T0.500S', \n",
    "    'T0.550S', 'T0.600S', 'T0.650S', 'T0.667S', 'T0.700S', 'T0.750S', \n",
    "    'T0.800S', 'T0.850S', 'T0.900S', 'T0.950S', 'T1.000S', 'T1.100S', \n",
    "    'T1.200S', 'T1.300S', 'T1.400S', 'T1.500S', 'T1.600S', 'T1.700S', \n",
    "    'T1.800S', 'T1.900S', 'T2.000S', 'T2.200S', 'T2.400S', 'T2.500S', \n",
    "    'T2.600S', 'T2.800S', 'T3.000S', 'T3.200S', 'T3.400S', 'T3.500S', \n",
    "    'T3.600S', 'T3.800S', 'T4.000S', 'T4.200S', 'T4.400S', 'T4.600S', \n",
    "    'T4.800S', 'T5.000S', 'T5.500S', 'T6.000S', 'T6.500S', 'T7.000S', \n",
    "    'T7.500S', 'T8.000S', 'T8.500S', 'T9.000S', 'T9.500S', 'T10.000S', \n",
    "    'T11.000S', 'T12.000S', 'T13.000S', 'T14.000S', 'T15.000S', 'T20.000S',\n",
    "]\n",
    "\n",
    "columns = features + measures\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voUdlhvO6iLS"
   },
   "source": [
    "# Preprocessing v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSbqG6vk6cCq"
   },
   "outputs": [],
   "source": [
    "def cv2number(item):\n",
    "    try:\n",
    "        item = int(item)\n",
    "    except:\n",
    "        item = 0\n",
    "    \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TYwggZGH6ggS",
    "outputId": "b9a67c2b-b812-423d-c5ac-8224786ed4d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13076"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [list(data.loc[data[column].apply(cv2number) == -999].index) for column in columns]\n",
    "indices = [ind for sub_ind in indices for ind in sub_ind]\n",
    "indices = list(set(indices))\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H97OcabV6lWB"
   },
   "outputs": [],
   "source": [
    "new_data = data.drop(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "gdazMM3L6nqx",
    "outputId": "0857653d-8623-4973-d430-85405b4ba5a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Earthquake Magnitude</th>\n",
       "      <th>Dip (deg)</th>\n",
       "      <th>Mechanism Based on Rake Angle</th>\n",
       "      <th>ClstD (km)</th>\n",
       "      <th>FW/HW Indicator</th>\n",
       "      <th>Vs30 (m/s) selected for analysis</th>\n",
       "      <th>Idirectivity</th>\n",
       "      <th>PGA (g)</th>\n",
       "      <th>PGV (cm/sec)</th>\n",
       "      <th>PGD (cm)</th>\n",
       "      <th>...</th>\n",
       "      <th>T8.500S</th>\n",
       "      <th>T9.000S</th>\n",
       "      <th>T9.500S</th>\n",
       "      <th>T10.000S</th>\n",
       "      <th>T11.000S</th>\n",
       "      <th>T12.000S</th>\n",
       "      <th>T13.000S</th>\n",
       "      <th>T14.000S</th>\n",
       "      <th>T15.000S</th>\n",
       "      <th>T20.000S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "      <td>593.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157020</td>\n",
       "      <td>10.05400</td>\n",
       "      <td>3.005200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>551.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.64978</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.57</td>\n",
       "      <td>0</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040961</td>\n",
       "      <td>2.79070</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.98</td>\n",
       "      <td>0</td>\n",
       "      <td>213.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.64551</td>\n",
       "      <td>0.056359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.58</td>\n",
       "      <td>0</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>6.56390</td>\n",
       "      <td>0.733060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Earthquake Magnitude  Dip (deg)  Mechanism Based on Rake Angle  ClstD (km)  \\\n",
       "0                   6.0       75.0                              0        2.86   \n",
       "1                   6.0       75.0                              0        2.92   \n",
       "2                   5.8       90.0                              0       71.57   \n",
       "3                   5.0       90.0                              0       34.98   \n",
       "4                   5.5       90.0                              0       53.58   \n",
       "\n",
       "   FW/HW Indicator  Vs30 (m/s) selected for analysis  Idirectivity   PGA (g)  \\\n",
       "0                0                            593.35             0  0.157020   \n",
       "1                0                            551.82             0  0.046423   \n",
       "2                0                            219.31             0  0.040961   \n",
       "3                0                            213.44             0  0.018449   \n",
       "4                0                            219.31             0  0.122180   \n",
       "\n",
       "   PGV (cm/sec)  PGD (cm)    ...      T8.500S   T9.000S   T9.500S  T10.000S  \\\n",
       "0      10.05400  3.005200    ...     0.001521  0.001368  0.001237  0.001123   \n",
       "1       0.64978  0.035305    ...     0.000021  0.000019  0.000017  0.000015   \n",
       "2       2.79070  0.402240    ...     0.000255  0.000226  0.000201  0.000180   \n",
       "3       0.64551  0.056359    ...     0.000031  0.000027  0.000024  0.000022   \n",
       "4       6.56390  0.733060    ...     0.000401  0.000348  0.000309  0.000276   \n",
       "\n",
       "   T11.000S  T12.000S  T13.000S  T14.000S  T15.000S  T20.000S  \n",
       "0  0.000938  0.000794  0.000681  0.000591  0.000517  0.000295  \n",
       "1  0.000012  0.000010  0.000009  0.000008  0.000007  0.000004  \n",
       "2  0.000147  0.000122  0.000103  0.000088  0.000077  0.000044  \n",
       "3  0.000018  0.000016  0.000013  0.000012  0.000010  0.000006  \n",
       "4  0.000228  0.000193  0.000166  0.000144  0.000126  0.000072  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_fw_hw = list(new_data['FW/HW Indicator'].unique())\n",
    "new_data['FW/HW Indicator'] = new_data['FW/HW Indicator'].apply(lambda i: unique_fw_hw.index(i))\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubS02o2-6ot5"
   },
   "outputs": [],
   "source": [
    "new_data.to_excel(os.path.join(current_dir + 'nga_west_v2.xlsx'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V14ZPgMICoc0"
   },
   "source": [
    "# Load the sanitized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "YuxZiMH5EzaI",
    "outputId": "2f40508b-f16b-4aaa-e717-6c4318142779"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Earthquake Magnitude</th>\n",
       "      <th>Dip (deg)</th>\n",
       "      <th>Mechanism Based on Rake Angle</th>\n",
       "      <th>ClstD (km)</th>\n",
       "      <th>FW/HW Indicator</th>\n",
       "      <th>Vs30 (m/s) selected for analysis</th>\n",
       "      <th>Idirectivity</th>\n",
       "      <th>PGA (g)</th>\n",
       "      <th>PGV (cm/sec)</th>\n",
       "      <th>PGD (cm)</th>\n",
       "      <th>...</th>\n",
       "      <th>T8.500S</th>\n",
       "      <th>T9.000S</th>\n",
       "      <th>T9.500S</th>\n",
       "      <th>T10.000S</th>\n",
       "      <th>T11.000S</th>\n",
       "      <th>T12.000S</th>\n",
       "      <th>T13.000S</th>\n",
       "      <th>T14.000S</th>\n",
       "      <th>T15.000S</th>\n",
       "      <th>T20.000S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "      <td>593.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157020</td>\n",
       "      <td>10.05400</td>\n",
       "      <td>3.005200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>551.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.64978</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.57</td>\n",
       "      <td>0</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040961</td>\n",
       "      <td>2.79070</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.98</td>\n",
       "      <td>0</td>\n",
       "      <td>213.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.64551</td>\n",
       "      <td>0.056359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.58</td>\n",
       "      <td>0</td>\n",
       "      <td>219.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>6.56390</td>\n",
       "      <td>0.733060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Earthquake Magnitude  Dip (deg)  Mechanism Based on Rake Angle  ClstD (km)  \\\n",
       "0                   6.0       75.0                              0        2.86   \n",
       "1                   6.0       75.0                              0        2.92   \n",
       "2                   5.8       90.0                              0       71.57   \n",
       "3                   5.0       90.0                              0       34.98   \n",
       "4                   5.5       90.0                              0       53.58   \n",
       "\n",
       "   FW/HW Indicator  Vs30 (m/s) selected for analysis  Idirectivity   PGA (g)  \\\n",
       "0                0                            593.35             0  0.157020   \n",
       "1                0                            551.82             0  0.046423   \n",
       "2                0                            219.31             0  0.040961   \n",
       "3                0                            213.44             0  0.018449   \n",
       "4                0                            219.31             0  0.122180   \n",
       "\n",
       "   PGV (cm/sec)  PGD (cm)    ...      T8.500S   T9.000S   T9.500S  T10.000S  \\\n",
       "0      10.05400  3.005200    ...     0.001521  0.001368  0.001237  0.001123   \n",
       "1       0.64978  0.035305    ...     0.000021  0.000019  0.000017  0.000015   \n",
       "2       2.79070  0.402240    ...     0.000255  0.000226  0.000201  0.000180   \n",
       "3       0.64551  0.056359    ...     0.000031  0.000027  0.000024  0.000022   \n",
       "4       6.56390  0.733060    ...     0.000401  0.000348  0.000309  0.000276   \n",
       "\n",
       "   T11.000S  T12.000S  T13.000S  T14.000S  T15.000S  T20.000S  \n",
       "0  0.000938  0.000794  0.000681  0.000591  0.000517  0.000295  \n",
       "1  0.000012  0.000010  0.000009  0.000008  0.000007  0.000004  \n",
       "2  0.000147  0.000122  0.000103  0.000088  0.000077  0.000044  \n",
       "3  0.000018  0.000016  0.000013  0.000012  0.000010  0.000006  \n",
       "4  0.000228  0.000193  0.000166  0.000144  0.000126  0.000072  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(os.path.join(current_dir + 'nga_west_v2.xlsx'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nkLu3iD6pyy"
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Earthquake Magnitude', \n",
    "    'Dip (deg)', \n",
    "    'Mechanism Based on Rake Angle', \n",
    "    'ClstD (km)', \n",
    "    'FW/HW Indicator',\n",
    "    'Vs30 (m/s) selected for analysis',\n",
    "    # 'Idirectivity'\n",
    "]\n",
    "measures = [\n",
    "    'PGA (g)', 'PGV (cm/sec)', 'PGD (cm)', 'T0.010S', 'T0.020S', 'T0.022S', \n",
    "    'T0.025S', 'T0.029S', 'T0.030S', 'T0.032S', 'T0.035S', 'T0.036S', \n",
    "    'T0.040S', 'T0.042S', 'T0.044S', 'T0.045S', 'T0.046S', 'T0.048S', \n",
    "    'T0.050S', 'T0.055S', 'T0.060S', 'T0.065S', 'T0.067S', 'T0.070S', \n",
    "    'T0.075S', 'T0.080S', 'T0.085S', 'T0.090S', 'T0.095S', 'T0.100S', \n",
    "    'T0.110S', 'T0.120S', 'T0.130S', 'T0.133S', 'T0.140S', 'T0.150S', \n",
    "    'T0.160S', 'T0.170S', 'T0.180S', 'T0.190S', 'T0.200S', 'T0.220S', \n",
    "    'T0.240S', 'T0.250S', 'T0.260S', 'T0.280S', 'T0.290S', 'T0.300S', \n",
    "    'T0.320S', 'T0.340S', 'T0.350S', 'T0.360S', 'T0.380S', 'T0.400S', \n",
    "    'T0.420S', 'T0.440S', 'T0.450S', 'T0.460S', 'T0.480S', 'T0.500S', \n",
    "    'T0.550S', 'T0.600S', 'T0.650S', 'T0.667S', 'T0.700S', 'T0.750S', \n",
    "    'T0.800S', 'T0.850S', 'T0.900S', 'T0.950S', 'T1.000S', 'T1.100S', \n",
    "    'T1.200S', 'T1.300S', 'T1.400S', 'T1.500S', 'T1.600S', 'T1.700S', \n",
    "    'T1.800S', 'T1.900S', 'T2.000S', 'T2.200S', 'T2.400S', 'T2.500S', \n",
    "    'T2.600S', 'T2.800S', 'T3.000S', 'T3.200S', 'T3.400S', 'T3.500S', \n",
    "    'T3.600S', 'T3.800S', 'T4.000S', 'T4.200S', 'T4.400S', 'T4.600S', \n",
    "    'T4.800S', 'T5.000S', 'T5.500S', 'T6.000S', 'T6.500S', 'T7.000S', \n",
    "    'T7.500S', 'T8.000S', 'T8.500S', 'T9.000S', 'T9.500S', 'T10.000S', \n",
    "    'T11.000S', 'T12.000S', 'T13.000S', 'T14.000S', 'T15.000S', 'T20.000S',\n",
    "]\n",
    "\n",
    "columns = features + measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PiABQsjU6sDg",
    "outputId": "d714c2dc-f9e4-4da0-bd5c-9a855ede3e2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv2number(item):\n",
    "    try:\n",
    "        item = int(item)\n",
    "    except:\n",
    "        item = 0\n",
    "    \n",
    "    return item\n",
    "\n",
    "indices = [list(data.loc[data[column].apply(cv2number) == -999].index) for column in columns]\n",
    "indices = [ind for sub_ind in indices for ind in sub_ind]\n",
    "indices = list(set(indices))\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeBjdUAJC1KB"
   },
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "Y = data[measures[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "zNAirIfeC1RC",
    "outputId": "c26d9e8a-c7e7-4725-9ca6-73f7866866a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Earthquake Magnitude</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>6.265542</td>\n",
       "      <td>0.871857</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.800</td>\n",
       "      <td>6.300</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dip (deg)</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>56.365276</td>\n",
       "      <td>22.111235</td>\n",
       "      <td>10.00</td>\n",
       "      <td>36.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mechanism Based on Rake Angle</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>1.523511</td>\n",
       "      <td>1.184769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClstD (km)</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>121.120349</td>\n",
       "      <td>117.919620</td>\n",
       "      <td>0.05</td>\n",
       "      <td>43.705</td>\n",
       "      <td>91.875</td>\n",
       "      <td>171.3450</td>\n",
       "      <td>1532.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FW/HW Indicator</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>0.839319</td>\n",
       "      <td>0.657218</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vs30 (m/s) selected for analysis</th>\n",
       "      <td>8464.0</td>\n",
       "      <td>410.456618</td>\n",
       "      <td>165.576299</td>\n",
       "      <td>89.32</td>\n",
       "      <td>300.220</td>\n",
       "      <td>376.960</td>\n",
       "      <td>498.1225</td>\n",
       "      <td>2100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count        mean         std    min  \\\n",
       "Earthquake Magnitude              8464.0    6.265542    0.871857   3.70   \n",
       "Dip (deg)                         8464.0   56.365276   22.111235  10.00   \n",
       "Mechanism Based on Rake Angle     8464.0    1.523511    1.184769   0.00   \n",
       "ClstD (km)                        8464.0  121.120349  117.919620   0.05   \n",
       "FW/HW Indicator                   8464.0    0.839319    0.657218   0.00   \n",
       "Vs30 (m/s) selected for analysis  8464.0  410.456618  165.576299  89.32   \n",
       "\n",
       "                                      25%      50%       75%      max  \n",
       "Earthquake Magnitude                5.800    6.300    6.8000     7.90  \n",
       "Dip (deg)                          36.000   50.000   78.0000    90.00  \n",
       "Mechanism Based on Rake Angle       0.000    2.000    2.0000     4.00  \n",
       "ClstD (km)                         43.705   91.875  171.3450  1532.66  \n",
       "FW/HW Indicator                     0.000    1.000    1.0000     3.00  \n",
       "Vs30 (m/s) selected for analysis  300.220  376.960  498.1225  2100.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Q1jdzydFC1OF",
    "outputId": "9119e859-1d3c-44c4-9d9d-e741dbe6a0bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8464.000000\n",
       "mean        0.064788\n",
       "std         0.114333\n",
       "min         0.000008\n",
       "25%         0.008386\n",
       "50%         0.023390\n",
       "75%         0.071355\n",
       "max         1.768300\n",
       "Name: PGA (g), dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rw_gAODBC5mF"
   },
   "source": [
    "# Preprocessing v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OfKu2fO6C3nL",
    "outputId": "4ca75454-2b3a-4edd-9e4f-4e9dc106b4a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape (8294, 6) Lable Shape (8294,)\n",
      "Validation Features Shape (119, 6) Lable Shape (119,)\n",
      "Test Features Shape (51, 6) Lable Shape (51,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.02, random_state=42)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.7, random_state=102)\n",
    "\n",
    "print('Train Features Shape {} Lable Shape {}'.format(X_train.shape, y_train.shape))\n",
    "print('Validation Features Shape {} Lable Shape {}'.format(X_validation.shape, y_validation.shape))\n",
    "print('Test Features Shape {} Lable Shape {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aLLb_kACC3sE",
    "outputId": "bc35cc9a-fa5d-46da-9871-dcb2c1f60a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8294, 1)\n",
      "(119, 1)\n",
      "(51, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train_data = y_train.as_matrix().reshape((-1, 1))\n",
    "y_validation_data = y_validation.as_matrix().reshape((-1, 1))\n",
    "y_test_data = y_test.as_matrix().reshape((-1, 1))\n",
    "\n",
    "print(y_train_data.shape)\n",
    "print(y_validation_data.shape)\n",
    "print(y_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xSQidlW6DARa",
    "outputId": "e22025bf-ffa9-4901-d019-5b44bfff7ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8294, 6)\n",
      "(119, 6)\n",
      "(51, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_data = X_train.as_matrix()\n",
    "X_validation_data = X_validation.as_matrix()\n",
    "X_test_data = X_test.as_matrix()\n",
    "\n",
    "print(X_train_data.shape)\n",
    "print(X_validation_data.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3d6P3Id6zce"
   },
   "source": [
    "# Implement the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfhZJNejDE3U"
   },
   "outputs": [],
   "source": [
    "class DNNLayer(object):\n",
    "    def __init__(self, units, activation=None, name=None, kernel_initializer=None, bias_initializer=None, **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "        self.name = name\n",
    "        self.kernel_initializer = xavier_initializer() if kernel_initializer is None else kernel_initializer\n",
    "        self.bias_initializer = xavier_initializer() if bias_initializer is None else bias_initializer\n",
    "        self.use_bias = kwargs.get('use_bias', True)\n",
    "        self.kernel_regularizer = kwargs.get('kernel_regularizer', None)\n",
    "        self.bias_regularizer = kwargs.get('bias_regularizer', None)\n",
    "        self.activity_regularizer = kwargs.get('activity_regularizer', None)\n",
    "        self.kernel_constraint = kwargs.get('kernel_constraint', None)\n",
    "        self.bias_constraint = kwargs.get('bias_constraint', None)\n",
    "        self.trainable = kwargs.get('trainable', True)\n",
    "        self.reuse = kwargs.get('reuse', None)\n",
    "\n",
    "    def layer(self):\n",
    "        layer = layers.Dense(units=self.units,\n",
    "                             activation=self.activation,\n",
    "                             use_bias=self.use_bias,\n",
    "                             kernel_initializer=self.kernel_initializer,\n",
    "                             bias_initializer=self.bias_initializer,\n",
    "                             kernel_regularizer=self.kernel_regularizer,\n",
    "                             bias_regularizer=self.bias_regularizer,\n",
    "                             activity_regularizer=self.activity_regularizer,\n",
    "                             kernel_constraint=self.kernel_constraint,\n",
    "                             bias_constraint=self.bias_constraint,\n",
    "                             trainable=self.trainable,\n",
    "                             name=self.name,\n",
    "                             _scope=self.name,\n",
    "                             _reuse=self.reuse)\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def build(self, inputs):\n",
    "        return self.layer().apply(inputs)\n",
    "    \n",
    "    \n",
    "class RNNR(object):\n",
    "    verbose_indent = 35\n",
    "\n",
    "    def __init__(self,\n",
    "                 inputs_steps,\n",
    "                 inputs_size,\n",
    "                 outputs_steps,\n",
    "                 outputs_size,\n",
    "                 cell_units=100,\n",
    "                 batch_size=1,\n",
    "                 lr=1e-3,\n",
    "                 lr_decay=.9,\n",
    "                 lr_decay_step=100,\n",
    "                 loss_type='',\n",
    "                 optimizer_type='',\n",
    "                 keep_prob=1.,\n",
    "                 out_dir='runs',\n",
    "                 checkpoint_dir='checkpoints',\n",
    "                 num_checkpoints=5):\n",
    "\n",
    "        self.inputs_size = inputs_size\n",
    "        self.inputs_steps = inputs_steps\n",
    "        self.outputs_size = outputs_size\n",
    "        self.outputs_steps = outputs_steps\n",
    "\n",
    "        self.cell_units = cell_units\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.out_dir = out_dir\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.lr_decay_step = lr_decay_step\n",
    "        self.loss_type = loss_type\n",
    "        self.optimizer_type = optimizer_type\n",
    "\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_checkpoints = num_checkpoints\n",
    "\n",
    "        self.loss = None\n",
    "\n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "\n",
    "    def arch(self):\n",
    "        # Tensors where we will feed the data into graph\n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, self.inputs_steps, self.inputs_size], name='inputs')\n",
    "        self.outputs = tf.placeholder(tf.float32, shape=[None, self.outputs_steps, self.outputs_size], name='outputs')\n",
    "        self.outputs_r = tf.reshape(self.outputs, [-1, self.outputs_size], name='outputs_r')\n",
    "\n",
    "        # Inputs operations\n",
    "        self.inputs_r = tf.reshape(self.inputs, [-1, self.inputs_size], name='inputs_reshape')\n",
    "        self.inputs_l = DNNLayer(\n",
    "            self.cell_units,\n",
    "            kernel_initializer=tf.random_normal_initializer(mean=0., stddev=1.),\n",
    "            bias_initializer=tf.constant_initializer(.1),\n",
    "            name='inputs_layer').build(self.inputs_r)\n",
    "        self.inputs_l_r = tf.reshape(\n",
    "            self.inputs_l, [-1, self.inputs_steps, self.cell_units], name='inputs_layer_reshape')\n",
    "\n",
    "        # Cell operations\n",
    "        self.cell = tf.nn.rnn_cell.LSTMCell(self.cell_units, name='cell')\n",
    "        # self.cell = tf.nn.rnn_cell.GRUCell(self.cell_units, name='cell')\n",
    "        self.cell = tf.nn.rnn_cell.DropoutWrapper(self.cell, input_keep_prob=self.keep_prob)\n",
    "        self.cell_init_state = self.cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn(\n",
    "            cell=self.cell,\n",
    "            inputs=self.inputs_l_r,\n",
    "            initial_state=self.cell_init_state)\n",
    "        self.cell_outputs_r = tf.reshape(self.cell_outputs, [-1, self.cell_units], name='cell_outputs_r')\n",
    "\n",
    "        self.logits = DNNLayer(\n",
    "            units=self.outputs_size,\n",
    "            name='logits').build(self.cell_outputs_r)\n",
    "\n",
    "        self.losses, self.loss = self.compute_loss(self.logits)\n",
    "\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(\n",
    "            learning_rate=self.lr,\n",
    "            global_step=self.global_step,\n",
    "            decay_rate=self.lr_decay,\n",
    "            decay_steps=self.lr_decay_step,\n",
    "            staircase=True\n",
    "        )\n",
    "\n",
    "    def optimization(self, lr):\n",
    "        if self.optimizer_type.lower() == 'adadelta':\n",
    "            return tf.train.AdadeltaOptimizer(learning_rate=lr)\n",
    "\n",
    "        elif self.optimizer_type.lower() == 'adam':\n",
    "            return tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "        elif self.optimizer_type.lower() == 'rmsprop':\n",
    "            return tf.train.RMSPropOptimizer(learning_rate=lr)\n",
    "\n",
    "        else:\n",
    "            return tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "\n",
    "    @staticmethod\n",
    "    def ms_error(labels, logits):\n",
    "        # labels = tf.log(labels)\n",
    "        # logits = tf.log(logits)\n",
    "        return tf.square(tf.subtract(labels, logits))\n",
    "\n",
    "    @staticmethod\n",
    "    def mse_error(labels, logits):\n",
    "        ms = tf.square(tf.subtract(labels, logits))\n",
    "        return tf.reduce_mean(ms)\n",
    "\n",
    "    @staticmethod\n",
    "    def rmse_error(labels, logits):\n",
    "        mse = tf.reduce_mean(tf.square(tf.subtract(labels, logits)))\n",
    "        return tf.sqrt(mse)\n",
    "\n",
    "    @staticmethod\n",
    "    def error(loss_type=''):\n",
    "        if loss_type.lower() == 'ms':\n",
    "            return RNNR.ms_error\n",
    "        elif loss_type.lower() == 'mse':\n",
    "            return RNNR.mse_error\n",
    "        elif loss_type.lower() == 'rmse':\n",
    "            return RNNR.rmse_error\n",
    "        else:\n",
    "            return RNNR.ms_error\n",
    "    \n",
    "    def compute_loss(self, logits):\n",
    "        loss_logits = tf.reshape(logits, [-1], name='loss_logits')\n",
    "        loss_targets = tf.reshape(self.outputs, [-1], name='loss_logits')\n",
    "        loss_weights = tf.ones([self.batch_size * self.outputs_size], name='loss_weights')\n",
    "\n",
    "        losses = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "            logits=[loss_logits],\n",
    "            targets=[loss_targets],\n",
    "            weights=[loss_weights],\n",
    "            average_across_timesteps=True,\n",
    "            softmax_loss_function=self.error(self.loss_type),\n",
    "            name='losses')\n",
    "\n",
    "        loss = tf.div(tf.reduce_sum(losses, name='losses_sum'), self.batch_size, name='average_loss')\n",
    "\n",
    "        return losses, loss\n",
    "\n",
    "    def operation(self):\n",
    "        # Define Training procedure\n",
    "        self.optimizer = self.optimization(lr=self.lr)\n",
    "        self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "        self.train_op = self.optimizer.apply_gradients(self.grads_and_vars, global_step=self.global_step)\n",
    "\n",
    "        # Keep track of gradient values and sparsity (optional)\n",
    "        grad_summaries = []\n",
    "        for g, v in self.grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram('{}/grad/hist'.format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar('{}/grad/sparsity'.format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        self.grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        self.out_dir = os.path.abspath(self.out_dir)\n",
    "        print('Writing to {}\\n'.format(self.out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        self.loss_summary = tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "        self.train_summary_op = tf.summary.merge([self.loss_summary, self.grad_summaries_merged])\n",
    "        self.validation_summary_op = tf.summary.merge([self.loss_summary])\n",
    "\n",
    "        # Train Summaries\n",
    "        self.train_summary_dir = os.path.join(self.out_dir, 'summaries', 'train')\n",
    "        self.train_summary_writer = tf.summary.FileWriter(self.train_summary_dir, self.session.graph)\n",
    "\n",
    "        # Test summaries\n",
    "        self.validation_summary_dir = os.path.join(self.out_dir, 'summaries', 'validation')\n",
    "        self.validation_summary_writer = tf.summary.FileWriter(self.validation_summary_dir, self.session.graph)\n",
    "\n",
    "        # Checkpoint directory. TensorFlow assumes this directory already exists so we need to create it\n",
    "        self.checkpoint_dir = os.path.abspath(os.path.join(self.out_dir, self.checkpoint_dir))\n",
    "        self.checkpoint_prefix = os.path.join(self.checkpoint_dir, 'model')\n",
    "        if not os.path.exists(self.checkpoint_dir):\n",
    "            os.makedirs(self.checkpoint_dir)\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=self.num_checkpoints)\n",
    "\n",
    "        # Initialize all variables\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def build(self):\n",
    "        print('Building the ANN...')\n",
    "        self.arch()\n",
    "        self.operation()\n",
    "\n",
    "    def batching(self, X, Y=None, batch_size=None):\n",
    "        batch_size = batch_size if batch_size else self.batch_size\n",
    "        shuffle = np.random.permutation(len(X))\n",
    "        start = 0\n",
    "        X = X[shuffle]\n",
    "\n",
    "        if Y is not None:\n",
    "            Y = Y[shuffle]\n",
    "\n",
    "            while start + batch_size <= len(X):\n",
    "                yield X[start:start + batch_size], Y[start:start + batch_size]\n",
    "                start += batch_size\n",
    "        else:\n",
    "            while start + batch_size <= len(X):\n",
    "                yield X[start:start + batch_size]\n",
    "                start += batch_size\n",
    "\n",
    "    def training(self, inputs, outputs, start_time):\n",
    "        feed_dict = {\n",
    "            self.inputs: inputs,\n",
    "            self.outputs: outputs,\n",
    "        }\n",
    "\n",
    "        _, step, summaries, loss = self.session.run([\n",
    "            self.train_op, self.global_step, self.train_summary_op, self.loss], feed_dict)\n",
    "\n",
    "        print('Epoch {:3}    Loss: {:>10.5f}    Epoch duration: {:>10.5f}s'.format(step, loss, time.time() - start_time))\n",
    "\n",
    "        self.train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        return self.train_summary_writer\n",
    "\n",
    "    def validating(self, inputs, outputs, writer=None):\n",
    "        feed_dict = {\n",
    "            self.inputs: inputs,\n",
    "            self.outputs: outputs\n",
    "        }\n",
    "\n",
    "        _, step, summaries, loss = self.session.run([\n",
    "            self.train_op, self.global_step, self.validation_summary_op, self.loss], feed_dict)\n",
    "\n",
    "        print('Evaluation =>    Epoch {:3}    Loss: {:>10.5f}'.format(step, loss))\n",
    "\n",
    "        if writer:\n",
    "            writer.add_summary(summaries, step)\n",
    "\n",
    "        return writer\n",
    "\n",
    "    def fit(self, train_data, valid_data=None, epochs=1, evaluate_ey=10, checkpoint_ey=10, shuffling=False):\n",
    "        X_tr, Y_tr = [None, None]\n",
    "        X_val, Y_val = [None, None]\n",
    "        validating = False\n",
    "        train_summary_writer = None\n",
    "        validation_summary_writer = None\n",
    "        path = None\n",
    "\n",
    "        if train_data is None or not isinstance(train_data, list):\n",
    "            raise Exception('Your train data must be a list that consists of [X, Y]')\n",
    "        elif not len(train_data) == 2:\n",
    "            raise Exception('Your train data must be a list that consists of [X, Y]')\n",
    "        else:\n",
    "            X_tr, Y_tr = train_data\n",
    "\n",
    "        if valid_data is not None:\n",
    "            if valid_data is None or not isinstance(valid_data, list):\n",
    "                raise Exception('Your validation data must be a list that consists of [X, Y]')\n",
    "            elif not len(valid_data) == 2:\n",
    "                raise Exception('Your validation data must be a list that consists of [X, Y]')\n",
    "            else:\n",
    "                X_val, Y_val = valid_data\n",
    "                validating = True\n",
    "\n",
    "        for epoch in range(epochs + 1):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if shuffling:\n",
    "                X_tr, Y_tr = shuffle(X_tr, Y_tr)\n",
    "\n",
    "                if validating:\n",
    "                    X_val, Y_val = shuffle(X_val, Y_val)\n",
    "\n",
    "            for X_tr_batch, Y_tr_batch in self.batching(X_tr, Y_tr, self.batch_size):\n",
    "\n",
    "                train_summary_writer = self.training(\n",
    "                    inputs=X_tr_batch,\n",
    "                    outputs=Y_tr_batch,\n",
    "                    start_time=start_time\n",
    "                )\n",
    "\n",
    "                current_step = tf.train.global_step(self.session, self.global_step)\n",
    "\n",
    "                if validating and current_step % evaluate_ey == 0:\n",
    "                    print('\\n')\n",
    "                    print('-' * self.verbose_indent, 'Validation', '-' * self.verbose_indent)\n",
    "\n",
    "                    for X_val_batch, Y_val_batch in self.batching(X_val, Y_val, self.batch_size):\n",
    "                        validation_summary_writer = self.validating(\n",
    "                            inputs=X_val_batch,\n",
    "                            outputs=Y_val_batch,\n",
    "                            writer=self.validation_summary_writer)\n",
    "\n",
    "                    out = self.verbose_indent * 2 + 2 + len('Validation')\n",
    "                    print('-' * out)\n",
    "                    print('\\n')\n",
    "\n",
    "                if current_step % checkpoint_ey == 0:\n",
    "                    path = self.saver.save(self.session, self.checkpoint_prefix, global_step=current_step)\n",
    "                    print('\\n')\n",
    "                    print('-' * self.verbose_indent, 'Saved model checkpoint to', '-' * self.verbose_indent)\n",
    "                    print(path)\n",
    "                    out = self.verbose_indent * 2 + 2 + len('Saved model checkpoint to')\n",
    "                    print('-' * out)\n",
    "                    print('\\n')\n",
    "\n",
    "        # Fix for google-colab\n",
    "        if train_summary_writer:\n",
    "            train_summary_writer.flush()\n",
    "            train_summary_writer.close()\n",
    "\n",
    "        if validation_summary_writer:\n",
    "            validation_summary_writer.flush()\n",
    "            validation_summary_writer.close()\n",
    "    \n",
    "    \n",
    "    def predicting(self, inputs, outputs, session, graph, checkpoint_dir=None):\n",
    "        checkpoint_dir = checkpoint_dir if checkpoint_dir else self.checkpoint_dir\n",
    "        checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        saver = tf.train.import_meta_graph('{}.meta'.format(checkpoint_file))\n",
    "        saver.restore(session, checkpoint_file)\n",
    "\n",
    "        operations = graph.get_operations()\n",
    "        _inputs = graph.get_operation_by_name('inputs').outputs[0]\n",
    "        # _outputs = graph.get_operation_by_name('outputs').outputs[0]\n",
    "        _logits = graph.get_operation_by_name('logits/BiasAdd').outputs[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        feed_dict = {_inputs: inputs}\n",
    "        logits = session.run(_logits, feed_dict=feed_dict)\n",
    "        \n",
    "        inputs = inputs.reshape((-1, inputs.shape[2]))\n",
    "        outputs = outputs.reshape((-1, outputs.shape[2]))\n",
    "        \n",
    "        print('Average Loss: {:>10.6f}'.format(mean_squared_error(outputs, logits)))\n",
    "        print()\n",
    "        \n",
    "        return inputs, outputs, logits, operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228551
    },
    "colab_type": "code",
    "id": "Aq6BPzpl6tAI",
    "outputId": "8b5c87a6-38e4-4e6a-808f-0f0ae9787ad4"
   },
   "outputs": [],
   "source": [
    "out_dir = os.path.abspath(os.path.join(current_dir, 'outputs', str(int(time.time()))))\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "\n",
    "model = RNNR(\n",
    "    inputs_steps=1, inputs_size=X_train_data.shape[1],\n",
    "    outputs_steps=1, outputs_size=y_train_data.shape[1],\n",
    "    cell_units=300,\n",
    "    batch_size=1,\n",
    "    lr=1e-3,\n",
    "    lr_decay=.8,\n",
    "    lr_decay_step=100,\n",
    "    loss_type='rmse',\n",
    "    optimizer_type='adam',\n",
    "    keep_prob=.5,\n",
    "    num_checkpoints=5,\n",
    "    out_dir=out_dir\n",
    ")\n",
    "\n",
    "train_data = [\n",
    "    X_train_data.reshape((-1, 1, X_train_data.shape[1])), \n",
    "    y_train_data.reshape((-1, 1, y_train_data.shape[1]))]\n",
    "\n",
    "valid_data = [\n",
    "    X_validation_data.reshape((-1, 1, X_validation_data.shape[1])), \n",
    "    y_validation_data.reshape((-1, 1, y_validation_data.shape[1]))]\n",
    "\n",
    "test_data = [\n",
    "    X_test_data.reshape((-1, 1, X_test_data.shape[1])), \n",
    "    y_test_data.reshape((-1, 1, y_test_data.shape[1]))]\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    session = tf.Session(config=session_conf)\n",
    "    \n",
    "    with session.as_default():\n",
    "        model.set_session(session)\n",
    "        model.build()\n",
    "        model.fit(\n",
    "            train_data=train_data, valid_data=valid_data, epochs=1, shuffling=True, evaluate_ey=50, checkpoint_ey=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eX9Ds7gDoan"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHbNkToo63Zw"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    session = tf.Session(config=session_conf)\n",
    "    \n",
    "    with session.as_default():\n",
    "        X, Y = next(model.batching(test_data[0], test_data[1]))\n",
    "        \n",
    "        _inputs, _outputs, _logits, _ = model.predicting(X, Y, session, graph)\n",
    "        \n",
    "#         checkpoint_dir = model.checkpoint_dir\n",
    "#         checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "#         saver = tf.train.import_meta_graph('{}.meta'.format(checkpoint_file))\n",
    "#         saver.restore(session, checkpoint_file)\n",
    "\n",
    "#         operations = graph.get_operations()\n",
    "#         _inputs = graph.get_operation_by_name('inputs').outputs[0]\n",
    "#         # _outputs = graph.get_operation_by_name('outputs').outputs[0]\n",
    "#         _logits = graph.get_operation_by_name('logits/BiasAdd').outputs[0]\n",
    "\n",
    "        \n",
    "        \n",
    "#         feed_dict = {_inputs: X}\n",
    "#         logits = session.run(_logits, feed_dict=feed_dict)\n",
    "        \n",
    "#         inputs = inputs.reshape((-1, inputs.shape[2]))\n",
    "#         outputs = outputs.reshape((-1, outputs.shape[2]))\n",
    "        \n",
    "#         print('Average Loss: {:>10.6f}'.format(mean_squared_error(outputs, logits)))\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Kp92Szziwoq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NGA-West2 Prediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
